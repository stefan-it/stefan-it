[![Bvarian Oberland](https://raw.githubusercontent.com/stefan-it/stefan-it/master/profile_header_27122024.jpg "Bavarian Oberland")](https://schweter.ml/)

### ðŸ‘‹ Hi there

I'm currently working on the awesome [Flair](https://github.com/flairNLP/flair)
library and love contributing to various open source projects.

### ðŸ“° Latest news

Latest news of new language models, PRs and many more!

* 21.12.2024: The [Turkish Model Zoo](https://github.com/stefan-it/turkish-bert) got new evaluations - performed with the awesome Flair library - see [here](https://github.com/stefan-it/turkish-bert).

* 09.12.2024: Public announcement of the [TensorFlow Model Garden LMs](https://github.com/stefan-it/model-garden-lms), including first FineWeb-LM releases on the [Model Hub](https://huggingface.co/collections/stefan-it/fineweb-lms-67561ed9d83c390221aaa2d4).

* 02.10.2024: Zeitungs-LM, a new language model trained on Historical German Newspapers is [out now](https://huggingface.co/stefan-it/zeitungs-lm-v1)!

* 04.07.2024: Flair fine-tuned NER models on the awesome [CleanCoNLL dataset](https://github.com/flairNLP/CleanCoNLL) are now available on the [Model Hub](https://huggingface.co/collections/stefan-it/fine-tuned-cleanconll-models-6685d2e4852db86b9ca90dba).

* 28.03.2024: New project: NER models on the recently released [CO-Fun](https://arxiv.org/abs/2403.15322) NER dataset. Repo is [here](https://github.com/stefan-it/co-funer) with a lot of fine-tuned models on the [Model Hub](https://huggingface.co/models?search=flair-co-funer).

* 23.12.2023: New project: NER Datasets for Historical German (HisGermaNER) is out and available on the Model Hub [here](https://huggingface.co/datasets/stefan-it/HisGermaNER).

* 11.10.2023: New launch of hmBench project: it benchmarks Historical Multilingual Language Models such as [hmBERT](https://huggingface.co/hmbert), [hmTEAMS](https://huggingface.co/hmteams) and [hmByT5](https://huggingface.co/hmbyt5), see [here](https://github.com/stefan-it/hmBench).

* 25.05.2023: New project: Historical Multilingual and Monolingual ELECTRA Models is released [here](https://github.com/stefan-it/hmELECTRA).

* 25.05.2023: Several ByT5 Historical Language Models are released under [hmByT5 Preliminary](https://huggingface.co/hmbyt5-preliminary) and [hmByT5](https://huggingface.co/hmbyt5) are released on the Hugging Face Model Hub.
              More information can be found [in this repository](https://github.com/stefan-it/hmByT5).

* 06.03.2023: Updated Ukrainian ELECTRA repository, see [here](https://github.com/stefan-it/ukrainian-electra).

* 05.02.2023: New repository on experiments for XLM-V ðŸ¤— Transformers Integeration, see [here](https://github.com/stefan-it/xlm-v-experiments).

* 03.02.2023: New repository for on-going evaluation of German T5 models on the GermEval 2014 NER task is up now! See [here](https://github.com/stefan-it/germeval-ner-t5).

* 28.01.2023: Start of new language models trained on the British Library corpus (model size ranges from 110M to 1B!), repository is [here](https://github.com/stefan-it/blbooks-lms).

* 23.01.2023: New German T5 models are released (trained on the the head and middle of GC4 corpus) and are available [here](https://huggingface.co/GermanT5).

* 09.06.2022: Preprint of our upcoming HIPE-2022 Working Notes paper is now available here: [hmBERT: Historical Multilingual Language Models for Named Entity Recognition](https://arxiv.org/abs/2205.15575).

* 20.02.2022: Check out our new [GermanT5 organization](https://github.com/GermanT5) - expect new T5 models for German soon!

* 14.12.2021: New badge: Member of [Hugging Face Supporter](https://github.com/Hugging-Face-Supporter) org now ðŸŽ‰

* 13.12.2021: Release of Historical Language Model for Dutch (trained on Delpher corpus) - see repo [here](https://github.com/stefan-it/delpher-lm).

* 06.12.2021: Release of smaller multilingual Historical Language Models (ranging from 2-8 layers) - see repo [here](https://github.com/stefan-it/clef-hipe/blob/main/hlms.md).

* 18.11.2021: Release of new multilingual and monolingual Historical Language Models - as preparation for upcoming CLEF-HIPE 2022 - see repo [here](https://github.com/stefan-it/clef-hipe/blob/main/hlms.md).

* 23.09.2021: Release of ConvBERTurk (cased and uncased) and ELECTRA (uncased) trained on Turkish part of mC4 corpus - see repo [here](https://github.com/stefan-it/turkish-bert).

* 07.09.2021: Release of new larger German GPT-2 model - see model hub card [here](https://huggingface.co/stefan-it/german-gpt2-larger).

* 17.08.2021: Release of new re-trained German GPT-2 model - see repo [here](https://github.com/stefan-it/german-gpt2).

* 05.07.2021: Preprint of the ICDAR 2021 paper ["Data Centric Domain Adaptation for Historical Text with OCR Errors"](https://arxiv.org/abs/2107.00927) together with Luisa MÃ¤rz, Nina Poerner, Benjamin Roth and Hinrich SchÃ¼tze is out now!

* 24.06.2021: Turkish Language Model Zoo repo got a new logo from [Merve Noyan](https://twitter.com/mervenoyann), please follow her! Additionally, a new Turkish ELECTRA model was released, that was trained on the Turkish part of multilingual C4 dataset. More details [here](https://github.com/stefan-it/turkish-bert).

* 03.05.2021: GC4LM: A Colossal (Biased) language model for German was released. Repo with more details [here](https://github.com/stefan-it/gc4lm).

* 27.04.2021: Our paper "Data Centric Domain Adaptation for Historical Text with OCR Errors" was accepted at ICDAR 2021. More details soon!

* 16.03.2021: Turkish model zoo is still growing! Public release of ConvBERTurk - see repo [here](https://github.com/stefan-it/turkish-bert).

* 07.02.2021: Public release of German Europeana DistilBERT and ConvBERT models. Repo with more information is [here](https://github.com/stefan-it/europeana-bert).

* 28.01.2021: Expect a new German Europeana ELECTRA Large model incl. a distilled German Europeana BERT model soon ðŸ¤—

* 16.11.2020: Public release of French Europeana BERT and ELECTRA models - see repository [here](https://github.com/stefan-it/europeana-bert).

* 16.11:2020: Public release of a German GPT-2 model (incl. fine-tuned model on Faust I and II). Repo with more information is available [here](https://github.com/stefan-it/german-gpt2).

* 11.11.2020: Public release of Ukrainian ELECTRA model. Repo is now available [here](https://github.com/stefan-it/ukrainian-electra).

* 11.11.2020: New workstation build (RTX 3090 and Ryzen 9 5900X) has completed! Expect a lot of new Flair/Transformers models in near future!

* 02.11.2020: Public release of Italian XXL ELECTRA model. New repo for Italian BERT and ELECTRA models is now available [here](https://github.com/stefan-it/italian-bertelectra) ðŸŽ‰

* 22.10.2020: Preprint of "German's Next Language Model" is now available [here](https://arxiv.org/abs/2010.10906). Models are also available on the [Hugging Face model hub](https://huggingface.co/models?search=deepset%2Fg) ðŸŽ‰

* 22.10.2020: Our shared task paper [Triple E - Effective Ensembling of Embeddings and Language Models for NER of Historical German](http://ceur-ws.org/Vol-2696/paper_173.pdf) together with [Luisa MÃ¤rz](https://github.com/LuisaMaerz) is released ðŸŽ‰

* 30.09.2020: "German's Next Language Model" together with [Branden Chan](https://github.com/brandenchan) and [Timo MÃ¶ller](https://github.com/Timoeller) was accepted at [COLING 2020](https://coling2020.org/)!
              Expect new language models for German on the Hugging Face model hub soon ðŸ¤—

* 23.09.2020: Flair in version 0.6.1 is [out now](https://github.com/flairNLP/flair/releases/tag/v0.6.1)!

* 02.09.2020: Slow response time - I'm currently focussing on EACL 2021. Expect great new things ðŸ˜Ž

* 18.08.2020: French BERT model, trained on Historical newspapers from Europeana:
  find the model [here](https://huggingface.co/dbmdz/bert-base-french-europeana-cased)
  and the corresponding repository [here](https://github.com/stefan-it/europeana-bert).

### ðŸ“ƒ Publications

* Lukas Thoma, Ivonne Weyers, Erion Ã‡ano, Stefan Schweter, Jutta L Mueller and Benjamin Roth. [CogMemLM: Human-Like Memory Mechanisms Improve Performance and Cognitive Plausibility of LLMs](https://aclanthology.org/2023.conll-babylm.15/). In Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning (CoNLL 2023).

* Stefan Schweter, Luisa MÃ¤rz, Katharina Schmid and Erion Ã‡ano. [hmBERT: Historical Multilingual Language Models for Named Entity Recognition](http://www.dei.unipd.it/~ferro/CLEF-WN-Drafts/CLEF2022/paper-87.pdf). In Experimental IR Meets Multilinguality, Multimodality, and Interaction - Proceedings of the Eleventh International Conference of the CLEF Association (CLEF 2022).

* Francesco De Toni, Christopher Akiki, Javier de la Rosa, ClÃ©mentine Fourrier, Enrique Manjavacas, Stefan Schweter and Daniel Van Strien. [Entities, Dates, and Languages: Zero-Shot on Historical Texts with T0](https://openreview.net/forum?id=BRzIS3GrIbc). Accepted at "Challenges & Perspectives in Creating Large Language Models" Workshop at ACL 2022.

* Luisa MÃ¤rz, Stefan Schweter, Nina Poerner, Benjamin Roth and Hinrich SchÃ¼tze. [Data Centric Domain Adaptation for Historical Text with OCR Errors](https://link.springer.com/chapter/10.1007/978-3-030-86331-9_48). In International Conference on Document Analysis and Recognition, ICDAR 2021.

* Branden Chan, Stefan Schweter and Timo MÃ¶ller. [German's Next Language Model](https://www.aclweb.org/anthology/2020.coling-main.598/). In Proceedings of the 28th International Conference on Computational Linguistics.

* Stefan Schweter and Luisa MÃ¤rz. [Triple E - Effective Ensembling of Embeddings and Language Models for NER of Historical German](http://ceur-ws.org/Vol-2696/paper_173.pdf). In Experimental IR Meets Multilinguality, Multimodality, and Interaction - Proceedings of the Eleventh International Conference of the CLEF Association (CLEF 2020).

* Stefan Schweter and Sajawel Ahmed. [Deep-EOS: General-Purpose Neural Networks for Sentence Boundary Detection](https://corpora.linguistik.uni-erlangen.de/data/konvens/proceedings/papers/KONVENS2019_paper_41.pdf). In Proceedings of the 15th Conference on Natural Language Processing (KONVENS 2019).

* Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter and Roland Vollgraf. [FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP](https://www.aclweb.org/anthology/N19-4010/). In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations).

* Stefan Schweter and Johannes Baiter. [Towards Robust Named Entity Recognition for Historic German](https://www.aclweb.org/anthology/W19-4312/). In Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019).

### ðŸ“ƒ Preprints

* Part of [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100).
* Stefan Schweter and Alan Akbik. [FLERT: Document-Level Features for Named Entity Recognition](https://arxiv.org/abs/2011.06993).

### ðŸ’¬ Contact

Please open an issue in the corresponding repository, tag me (@stefan-it) in
issues/prs/commits on GitHub or connect with me on [LinkedIn](https://www.linkedin.com/in/stefan-it/) :)
